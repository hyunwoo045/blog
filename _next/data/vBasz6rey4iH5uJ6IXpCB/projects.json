{"pageProps":{"allPostsData":[{"id":0,"title":"코맥스 클라우드 2.0 인증/연동 서버","date":"2023-04-14","tag":["Spring Boot","Spring Data JPA","Gitlab Pipeline","Docker","AWS ECS"],"content":"\n- 기간: 2022-04 ~ 2022-08, 약 5개월\n- 구성 인원: 1인\n- 주요 업무\n    - PHP to Java 기능 마이그레이션.\n    - Spring Boot 프로젝트 구성\n    - Dockerfile 작성 (빌드)\n    - Gitlab pipeline 코드 작성 (CI/CD 배포)\n    - AWS ECS Task 정의 및 서비스 생성 (클러스터 정의)\n- 결과: 코드 이관 완료 및 22년 10월 상용 기존 서비스 대체 배포 완료.\n- 개선점: MSA 내 타 구조와 동일한 언어 스펙으로 변경하여 유지 보수 측면에서 이점 확보.\n- 기술 스택\n    - Spring Boot (Java)\n    - Spring JPA (Hibernate, JPQL)\n    - Gitlab pipeline (CI/CD)\n    - Docker\n    - AWS ECS Cluster\n\n---\n\n# 프로젝트 소개\n\nMSA 로 구성된 자사 백엔드 클라우드 서비스는 대부분의 서버 바이너리가 Java 로 작성되어 있음에도 불구하고 인증(Auth), 연동(Group) 서버는\nPHP 코드로 작성되어 있었습니다. 이를 MSA 내 타 서버들과 동일한 언어 스펙으로 변경하는 것이 주 목적인 프로젝트입니다.\n\n기존 코드가 존재하긴 하나 신규 프로젝트나 다름 없었습니다. 좋은 프로젝트를 구성하기 위하여 어떤 점을 고려하고 실제 코드로 구현하였는지\n간단히 소개하도록 하겠습니다.\n\n---\n\n## 핵심 비즈니스 로직와의 코드 분리\n\n컨트롤러 메서드에는 최대한 핵심 비즈니스 로직만을 남기고 나머지 코드들은 모두 분리하는 것은 선택이 아닌 필수입니다.\n여기서 나머지 코드라 함은 가장 먼저 '로깅', '검증'과 같은 로직들이 생각이 납니다. 이러한 로직을 분리하여 별도 구현한다면\n가독성 향상되어 유지 보수 용이성을 확보할 수 있고 이 후 협업을 함에 있어 타인에게 코드를 이해시키기 쉽다는 장점을 얻을 수 있겠습니다.\n\n아래는 실제 기존 인증 서버 내 유저 아이디가 존재하는 지 검사하는 메서드의 PHP 코드를 일부 생략한 예시입니다.\n\n```php\nclass UserController extends BaseController {\n\n    public function userExistAction() {\n  \n        $this->view->disable();\n        $response = new Response();\n      \n        $rawBody = $this->request->getJsonRawBody(true);\n      \n        $client = CmxCommon::checkClientOrThrow($rawBody);\n      \n        $userId = $rawBody['user']['userId'];\n        if (StringUtil::isEmpty($userId)) throw new MissingMandatoryParameter(\"user.userId\");\n      \n        $users = User::getUsersByUserId($userId);\n      \n        if(sizeof($users) > 0) {\n            $response->setJsonContent(\n                [\n                    'resultCode' => ResultCode::NO_ERROR,\n                    'resultMessage' => '',\n                    'exist' => true\n                ]\n            );\n            return $response;\n        } else {\n            $response->setJsonContent(\n                [\n                    'resultCode' => ResultCode::NO_ERROR,\n                    'resultMessage' => '',\n                    'exist' => false\n                ]\n            );\n        }\n\n        return $response;\n    }\n}\n```\n\n이미 충분히 반복이 될만한 동작들은 메서드로 빠져있는 상태이며, 매우 읽기 좋은 상태의 코드였습니다. 이 정도의 코드를 그대로 옮겨 쓰더라도\n문제될 것 하나 없어 보입니다.\n\n하지만 앞서 말씀드린대로 **핵심 비즈니스 로직**만을 남기고 나머지 **검증 로직**들은 컨트롤러 메서드 스코프 안에서\n읽히지 않는 것이 좋겠습니다.\n\n### AOP\n\n처음 제시한 방안은 관점 지향 프로그래밍으로 코드를 분리하는 방법이었습니다.\n\n```java\nimport java.lang.annotation.ElementType;\nimport java.lang.annotation.Retention;\nimport java.lang.annotation.RetentionPolicy;\nimport java.lang.annotation.Target;\n\n@Target({ElementType.TYPE, ElementType.METHOD})\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface CheckClient {}\n```\n\n커스텀 어노테이션을 생성하고,\n\n```java\n@Aspect\n@Component\npublic class CheckClientAop extends BaseAop {\n    @Pointcut(\"@annotation(....annotation.CheckClient)\")\n    private void enableCheckClient() {}\n  \n    @Before(\"enableCheckClient()\")\n    public void checkClient(JoinPoint joinPoint) {\n        //... client 검증 로직\n    }\n}\n```\n\n`@CheckClient` 어노테이션이 달려 있는 핸들러가 실행되기 전에 Client 검증을 하도록 코드를 분리할 수 있었습니다.\n\n```java\n@Controller\n@RequestMapping('/user')\npublic class UserController {\n  \n    @Autowired\n    private UserService userService;\n  \n    @CheckClient\n    @GetMapping('/exist')\n    public boolean createUser(\n        @RequestBody UserExistReq body\n    ) {\n        String userId = body.getUserId();\n        User user = userService.getUserByUserId(userId);\n        return user != null;\n    }\n}\n```\n\n하지만 위 검증 로직은 후술할 이유로 드랍되었습니다. 현재 Aspect 메서드는 로깅 및 exception 처리에 사용되고 있습니다.\n\n아래는 로깅을 위해 Aspect 메서드를 사용한 예시입니다. 상세 코드는 생략합니다.\n\n```java\n@Aspect\n@Component\npublic class GlobalAspect {\n    @Order(0)\n    @Around(\"within(controller..*)\")\n    public Object controllerAspectProcessor(ProceedingJoinPoint joinPoint) {\n        HttpServletReqeust request = ((ServletRequestAttributes) RequestContextHolder.currentRequestAttributes()).getRequest();\n        StopWatch watch = new StopWatch();\n        try {\n            watch.start();\n            joinPoint.proceed();\n        } catch (Exception e) {\n            // handle exception\n        } finally {\n            watch.stop();\n            // log - request, watch.getTotalTimeMillis() 등...\n        }\n    }\n}\n```\n\n### 검증 AOP 를 드랍한 이유\n\n'검증'을 마친 후에는 요청자에 대한 정보를 얻을 수 있습니다. Request body 에 client 정보 (id, secret)을 명시했다면\nclient 에 대한 상세 정보를 데이터베이스에서 얻을 수 있고, Authorization 토큰을 가지고 들어왔다면 검증 과정에서 파싱하여\n유저 정보를 얻을 수 있습니다. 이러한 정보는 실제 핵심 비즈니스 로직에 사용되는 경우가 드물지 않습니다.\n\n하지만 Aspect 메서드를 통해 검증을 진행하였다면 클라이언트 혹은 유저 정보를 다시 컨트롤러 메서드로 넘겨주는 것이 쉽지 않습니다.\n아래는 초기에 Aspect 메서드에서 컨트롤러 메서드로 데이터를 넘겨주기 위해 실제로 초기에 제가 구성했던 구조입니다.\n\n```java\npublic class ThreadConst {\n    public static ThreadLocal<Client> client = new ThreadLocal<>();\n}\n```\n\n```java\n@Aspect\n@Component\npublic class CheckClientAop extends BaseAop {\n  \n    @Autowired\n    private ClientService clientService;\n  \n    @Pointcut(\"@annotation(....annotation.CheckClient)\")\n    private void enableCheckClient() {}\n  \n    @Before(\"enableCheckClient()\")\n    public void checkClient(JoinPoint joinPoint) {\n        Client client = clientService.checkClientValid();\n        ThreadConst.client.set(client);\n    }\n}\n```\n\n```java\n@Controller\n@RequestMapping('/user')\npublic class UserController {\n  \n    @PostMapping('/')\n    public void createUser() {\n        System.out.println(\"새로운 유저를 생성할 거에요!\");\n      \n        Client client = ThreadConst.client.get();\n    }\n}\n```\n\n`ThreadConst` 라는 스레드 로컬 값을 저장하기 위한 객체를 생성해서 분리 코드에서 스레드 로컬에 저장하고 실제 핸들러에서 꺼내쓰는\n방식이었습니다. 동작에는 문제가 없는 코드이지만 메모리 관리를 철저히 해야 한다는 점, 의도한 작동을 보장할 수 없다는 점 등\n전역 변수를 사용하였을 때의 문제점들을 이유로 지적받았습니다.\n\n이를 구현하는 좋은 방법으로 **Resolver** 를 선택하였습니다.\n\n### HandlerMethodArgumentResolver\n\n컨트롤러 메서드 인자값들의 전처리를 위한 인터페이스로 여러 기능을 수행할 수 있지만 메서드에 특정 어노테이션을\n붙혀서 원하는 데이터를 바인딩할 수 있다는 것을 활용하였습니다.\n\n`Header: Authorization` 에 Bearer 토큰 값을 검증하고 필요한 데이터를 컨트롤러에게 넘겨주는\n실제 코드를 간단히 요약한 것을 소개하겠습니다.\n\n```java\n// 바인딩 매개체로 사용할 어노테이션\n\n@Target({ElementType.PARAMETER})\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface AuthToken {\n    boolean required() default true;\n}\n```\n\n```java\n// Resolver 정의\n\n@Component\n@RequiredArgsConstructor\npublic class AuthTokenArgumentResolver implements HandlerMethodArgumentResolver {\n  \n    @Autowired\n    private TokenParser parser;\n  \n    // 이 메서드에서 처리 가능한 파라미터인지를 판단\n    @Override\n    public boolean supportsParameter(MethodParameter parameter) {\n        return parameter.getParameterAnnotation(AuthToken.class) != null;\n    }\n\n    // supportsParameter 에서 AuthToken 어노테이션이 달린 인자를 확인하고 Header 의 토큰값을 파싱하여 해당 인자에 바인딩.\n    @Override\n    public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception {\n        String authHeader = webRequest.getHeader(\"Authorization\");\n        if(authHeader != null) authHeader = authHeader.trim();\n        return parser.parse(authHeader);\n    }\n}\n```\n\n```java\n@Controller\n@RequestMapping('/user')\npublic class UserController {\n  \n    @PostMapping('/')\n    public void createUser(\n        @AuthToken Object token  // 컨트롤러 메서드에서 파싱되어 활용 가능한 객체를 인자로 받아 사용\n    ) {\n        String name = token.getUserName();\n    }\n}\n```\n\n이러한 방식으로 '검증'에 필요한 코드들을 핵심 비즈니스 로직과 분리하였습니다.\n\n---\n\n## 데이터베이스\n\n### JPA\n\n요구 사항 특징 상 복잡하거나 동적인 쿼리를 구현할 필요가 없고 또한 데이터 자체가 객체로써 특정할만한 역할을 수행하지 않기 때문에\n`mybatis` 등과 같은 ORM 개념이 없는 기술을 사용하더라도 문제될 것은 없었습니다만,\n개발자의 **개발 편의성**과 이 역시 **핵심 비즈니스 로직**에 집중할 수 있는 환경을 구성하기 위해 JPA 를 사용합니다.\n\n가장 무난한 `Hibernate` ORM 프레임워크를 채택하였으며 `JPQL` 로 쿼리를 구현합니다.\n\n### Replication\n\nRead-only 메서드가 압도적으로 많은 서비스 특성 상 실제 데이터베이스는 Master-Slave 구조로 분리되어 있고 Slave 데이터베이스가\nRead 트랜잭션을 담당하고 있습니다. 이에 대해서 Replication 설정이 필요합니다.\n\n```java\n@Configuration\npublic class MasterDataSourceConfig {\n\n    @Primary\n    @Bean(name = \"masterDataSource\")\n    @ConfigurationProperties(prefix = \"spring.datasource.master.hikari\")\n    public DataSource masterDataSource() {\n        return DataSourceBuilder.create()\n            .type(HikariDataSource.class)\n            .build();\n    }\n}\n```\n\n```java\n@Configuration\npublic class SlaveDataSourceConfig {\n\n    @Bean(name = \"slaveDataSource\")\n    @ConfigurationProperties(prefix = \"spring.datasource.slave.hikari\")\n    public DataSource slaveDataSource() {\n        return DataSourceBuilder.create()\n            .type(HikariDataSource.class)\n            .build();\n    }\n}\n```\n\nMaster 설정과 Slave 설정을 나누어 객체를 생성해줍니다. Property 설정에 따라 다른 DataSource 가 생성됩니다.\n\nDataSource 를 생성하였으니 라우팅 테이블과 같은 형태로 만들기 위한 설정을 해줍니다.\n\n```java\n// Transaction 성격에 따라 연결 유형을 결정할 수 있도록 설정\npublic class ReplicationRoutingDataSource extends AbstractRoutingDataSource {\n\n    @Override\n    protected Object determineCurrentLookupKey() {\n        TransactionSynchronizationManager.isCurrentTransactionReadOnly() ? DataSourceType.Slave : DataSourceType.Master;\n    }\n}\n```\n\n```java\npublic class RoutingDataSourceConfig {\n  \n    // Map 생성\n    @Bean(name = \"routingDataSource\")\n    public DataSource routingDataSource(\n        @Qualifier(\"masterDataSource\") final DataSource masterDataSource,\n        @Qualifier(\"slaveDataSource\") final DataSource slaveDataSource\n    ) {\n        ReplicationRoutingDataSource routingDataSource = new ReplicationRoutingDataSource();\n        Map<Object, Object> dataSourceMap = new HashMap<>();\n\n        dataSourceMap.put(DataSourceType.Master, masterDataSource);\n        if(useRdbSlave) dataSourceMap.put(DataSourceType.Slave, slaveDataSource);\n\n        routingDataSource.setTargetDataSources(dataSourceMap);\n        routingDataSource.setDefaultTargetDataSource(masterDataSource);\n\n        return routingDataSource;\n    }\n\n    // 트랜젝션이 생성될 때가 아니라 실제 쿼리가 발생할 때에 connection 을 점유하도록 설정\n    @Bean(name = \"dataSource\")\n    public DataSource dataSource(@Qualifier(\"routingDataSource\") DataSource routingDataSource) {\n        return new LazyConnectionDataSourceProxy(routingDataSource);\n    }\n\n    // EntityManagerFactory 설정\n    @Bean(name = \"jpaEntityManagerFactory\")\n    public LocalContainerEntityManagerFactoryBean entityManagerFactory(@Qualifier(\"dataSource\") DataSource dataSource) {\n        Map<String, Object> prop = new HashMap<>();\n        prop.put(\"hibernate.physical_naming_strategy\", SpringPhysicalNamingStrategy.class.getName());\n        prop.put(\"hibernate.implicit_naming_strategy\", SpringImplicitNamingStrategy.class.getName());\n        prop.put(\"hibernate.hbm2ddl.auto\", env.getProperty(\"spring.jpa.hibernate.ddl-auto\"));\n\n        LocalContainerEntityManagerFactoryBean em = new LocalContainerEntityManagerFactoryBean();\n        em.setJpaVendorAdapter(new HibernateJpaVendorAdapter());\n        em.setDataSource(dataSource);\n        em.setPackagesToScan(\"common.jpa.entity\", \"gauth.jpa.entity\");\n        em.setPersistenceUnitName(\"jpaEntityManager\");\n        em.setJpaPropertyMap(prop);\n\n        return em;\n    }\n\n    // JpaTransactionManager 구현 및 bean 으로 등록\n    @Bean(name = \"jpaTransactionManager\")\n    public PlatformTransactionManager jpaTransactionManager(EntityManagerFactory entityManagerFactory) {\n        JpaTransactionManager transactionManager = new JpaTransactionManager();\n        transactionManager.setEntityManagerFactory(entityManagerFactory);\n        return transactionManager;\n    }\n}\n```\n\n설정을 마쳤으니 마지막으로 컨트롤러 메서드 별로 트랜젝션의 성격을 정해주어 올바른 데이터베이스 인스턴스로 라우팅되도록 해주었습니다.\n\n```java\n@Controller\n@RequestMapping('/user')\npublic class UserController {\n  \n    @Transactional\n    @PostMapping('/')\n    public void createUser() {\n        // ...\n    }\n\n    @Transactional(readOnly = true)\n    @GetMapping('/')\n    public void getUserInfo() {\n        // ...\n    }\n}\n```\n\n## Exception\n\n예측 가능한 범위의 exception 들은 커스텀한 `RuntimeException` 을 던져 AOP 에서 알맞는 Response body 생성하여\n응답하도록 구성하였습니다.\n\n```java\npublic class BaseException extends RuntimeException {\n    public String code = \"9999\";\n    public String message = \"\";\n  \n    public BaseException(String code, String message) {\n        super(message);\n        this.code = code;\n        this.message = message;\n    }\n}\n```\n\n```java\n@Controller\n@RequestMapping('/user')\npublic class UserController {\n\n    @GetMapping('/')\n    public void getUserInfo(\n        @RequestBody UserReq body\n    ) {\n        // ...\n        User user = userService.getUserById(body.getUserId());\n        if (user == null) throw new BaseException(400, \"User ID is not found\");\n    }\n}\n```\n\n```java\npublic class GlobalExceptionHandler {\n    public static ResponseEntity<BaseResponse> handle(Exception e) {\n        if (e instanceof BaseException) {\n            code = ((BaseException) e).code;\n            message = ((BaseException) e).message;\n        }\n        return BaseResponse.toResponseEntity(code, message);\n    }\n}\n```\n\n```java\n@Aspect\n@Component\npublic class GlobalAspect {\n  \n    @Order(0)\n    @Around(\"within(controller..*)\")\n    public Object controllerAspect(ProceedingJoinPoint joinPoint) {\n        Object returnObject = null;\n        try {\n            returnObject = joinPoint.proceed();\n        } catch (Exception e) {\n            returnObject = GlobalExceptionHandler.handle(e);\n        }\n      \n        return returnObject;\n    }\n}\n```\n\nException 이 발생하더라도 원하는 형태의 응답이 내려가도록 처리할 수 있습니다.\n\n또한 프레임워크에서 발생시키는 exception 들의 경우도 커스텀한 exception 으로 처리할 필요가 있었기 때문에 `@ControllerAdvice` 객체를 통해 처리하도록 추가 작업하였습니다.\n\n```java\n@ControllerAdvice\npublic class GlobalExceptionHandler {\n    public static ResponseEntity<BaseResponse> handle(Exception e) {\n        if (e instanceof BaseException) {\n            code = ((BaseException) e).code;\n            message = ((BaseException) e).message;\n        }\n        return BaseResponse.toResponseEntity(code, message);\n    }\n  \n    /** \n     * RequestBody 어노테이션이 있는 컨트롤러 메서드임에도 불구하고 JSON body 가 없는 경우\n     */\n    @ExceptionHandler(HttpMessageNotReadableException.class)\n    @ResponseStatus(HttpStatus.BAD_REQUEST)\n    @ResponseBody\n    public ResponseEntity<BaseResponseDto> handle(HttpServletRequest req, HttpMessageNotReadableException e) {\n        return GlobalExceptionHandler.handle(new ParamVerifyException(\"Something is wrong with request body: \" + e.getMessage()));\n    }\n\n    /**\n     * RequestHeader 어노테이션으로 명시된 필수 입력 헤더가 비어 있는 경우\n     */\n    @ExceptionHandler(MissingRequestHeaderException.class)\n    @ResponseStatus(HttpStatus.OK)\n    @ResponseBody\n    public ResponseEntity<BaseResponseDto> handle(HttpServletRequest req, MissingRequestHeaderException e) {\n        return GlobalExceptionHandler.handle(new MissingMandatoryHeaderException(e.getMessage()));\n    }\n\n    /**\n     * RequestParam 어노테이션으로 명시된 필수 입력 파라미터가 누락된 경우\n     */\n    @ExceptionHandler(MissingServletRequestParameterException.class)\n    @ResponseStatus(HttpStatus.OK)\n    @ResponseBody\n    public ResponseEntity<BaseResponseDto> handle(HttpServletRequest req, MissingServletRequestParameterException e) {\n        return GlobalExceptionHandler.handle(req, new ParamVerifyException(e.getMessage()));\n    }\n}\n```\n\n위와 같은 방식으로 발생 가능한 Exception 을 최대한 고려하여 클라이언트에게 식별 가능한 응답이 내려가도록 구현하였습니다.\n\n## 빌드와 배포\n\nDocker 컨테이너를 통해 서비스를 구동하는 기존 다른 서버와 동일하게 배포 방식을 가져가야 했습니다. 그러기 위해서는\n아래와 같은 점들을 고려해야 했습니다.\n\n1. AWS ECS cluster 에 서비스가 등록될 예정이기 때문에 SSH 접속을 위한 조치가 필요\n2. ELK 구조를 통해 로그를 AWS OpenSearch 서비스에 적재하므로 filebeat 설정이 필요\n3. develop, stage, production 으로 3가지 환경이 나누어지므로 추가 설정이 필요\n\n도커파일 구성은 아래와 같습니다. 실제 코드를 생략하고 동작 순서를 간단히 설명합니다.\n\n```dockerfile\n# alpine 리눅스를 사용합니다.\nFROM alpine:3.15  \n# openjdk11-jre logrotate openssh filebeat 설치\n# project 내 key file 을 ADD 하고 권한 부여\n# JAVA_HOME 환경 변수 등록\n# project 내 바이너리 실행 script를 ADD (entrypoint.sh)\n# project 내 filebeat 설정 파일을 ADD 하고 필요한 권한을 부여\n# build 되어 있는 jar 파일을 ADD\nENTRYPOINT /root/entrypoint.sh\n```\n\n배포는 git commit push 시 pipeline 이 동작하도록 구성되어 있습니다. 팀 내 형상 관리는 gitlab 을 사용하고 있으며\ngitlab 의 CI/CD 는 pipeline 으로 구현됩니다. 아래는 실제 pipeline 코드에서 핵심 코드만 간추린 예시입니다.\n\n```yml\nstages:\n  - versioning\n  - build\n  - deploy\n\nversioning-job:\n  stage: versioning\n  script:\n    - CURR_VER=$(cat build.gradle | grep \"version =\" | sed -E 's/version = \"(.*)\"$/\\1/')\n\nbuild-job:\n  stage: build\n  script:\n    - ./gradlew build\n    - docker build . -t cloud-v2-gauth\n\ndeploy-job:\n  stage: deploy\n  needs: [ \"versioning-job\", \"build-job\" ]\n  script:\n    #   aws-cli ECR login | AWS docker login\n    - TAG=\"$CI_COMMIT_BRANCH\"\n    - >\n      if [ \"$CI_COMMIT_BRANCH\" = \"master\" ]; then\n        TAG=\"latest\"\n      fi\n  #   이미지를 AWS ECR 에 푸시\n  dependencies:\n    - build-job\n```\n\n이와 같이 구성하여 코드 푸시가 일어난다면 AWS ECR 에 이미지가 업데이트가 되고, 업데이트가 완료되면\n인스턴스 내에서 컨테이너 재시작 (개발 환경), 클러스터 서비스의 Task 에 새 배포를 적용하여 재시작(스테이지, 상용 환경)하는 것으로\n신규 버전의 어플리케이션을 배포합니다.\n"},{"id":2,"title":"관리자 페이지 - 운영 관제 시스템","date":"2023-03-11","tag":["Node.js","React","Redux","Express","ElasticSearch","Redis","MariaDB","Gitlab pipeline","Docker"],"content":"\n- 기간\n    - 초기 백엔드 프로젝트 구성 (2022년 8월, 2주)\n    - 트러블 슈팅, 코드 리팩토링 (2023년 2월 ~ 3월, 3주)\n- 구성 인원: 1인\n- 주요 업무\n    - 백엔드 초기 구조 구현\n    - 트러블 슈팅\n    - 프론트엔드 코드 리팩토링\n    - Gitlab pipeline 코드 및 Dockerfile 코드 수정\n- 결과: 버그 픽스 후 서비스 정상화 완료.\n- 기술 스택\n    - 프론트엔드\n        - React\n        - Redux\n    - 백엔드\n        - Express\n        - MariaDB\n        - ElasticSearch\n        - Redis\n    - Gitlab pipeline\n    - Docker\n\n서비스 장애 발생 시 장애 내용이 파악되지 않고 전 부서로 메일 및 JIRA 를 통해 무분별하게 전달되어\n업무 효율을 저하시키는 구조를 개선하고자 서비스 최전단에 어드민 페이지 형태의 관제 시스템을 배치하는 목적의 프로젝트입니다.\n외주 담당 프로젝트이지만 내부 사정으로 일부 업무를 지원하였습니다.\n\n## 백엔드 어플리케이션 초기 구조 구현\n\n백엔드 어플리케이션 기술 스택은 Javascript, Express 런타임을 채택합니다. 구현 자유도가 매우 높은 것이 장점이나\n코드를 아주 잘 짜지 않는다면 같은 코드여도 항상 같은 동작을 확신할 수 없다는 점, 타입 안정성 또한 확신할 수 없다는 점 등\n스택 자체가 매우 불안정하다고 느끼기 때문에 개인적으로 싫어합니다만, 외주 인력이 Javascript 외 기술을 사용할 수 없는 점 때문에\n해당 스택을 채택합니다.\n\n간단하게 디렉토리 구조를 정하고 서버 이니시에이팅 코드와 요구사항의 일부 코드를 구현한 후 인수인계 하는 것이 목표입니다.\n\n### 디렉토리 구조\n\n`/src` 디렉토리 내 아래와 같은 패키지들로 구성합니다.\n\n- `/api`: 아래 `/user`, `/resource` 등의 하위 폴더 내 각 controller, service, repository 를 포함하여 컨트롤러 메서드 전반에 필요한 기능을 구현\n- `/dto`: HTTP 통신에 필요한 Data 전송 객체의 구현. 대표적으로 AWS OpenSearch 로의 쿼리 Body 가 정의됨.\n- `/lib`: logger, database connection pool 등의 라이브러리 객체 구현\n- `/middleware`: request handler (AOP 객체), error interceptor 등의 미들웨어 함수 구현\n\n기타 `/common`, `/util`, `/env` 과 같은 디렉토리들을 구성하였습니다.\n\n### App 확장\n\n`Controller` 객체 의존성을 추가하고 `Middleware` 함수 의존성을 추가하여 Express 앱을 확장합니다.\n\n컨트롤러 객체 코드 예시입니다.\n\n```js\nexport default class UserController {\n    path = \"/user\";\n\n    router = Router();\n\n    constructor() {\n        this.initializeRoutes();\n    }\n\n    initializeRoutes = () => {\n        const router = Router();\n\n        router.get('/', this.getUser);\n\n        this.router.use(this.path, router);\n    }\n\n    getUser = (req, res) => {\n        const {userId} = req.params;\n        console.log('유저를 검색합니다~');\n    }\n}\n```\n\n위와 같은 컨트롤러를 앱이 생성될 때 배열 형태로 주입하여 의존성을 생성합니다.\n\n```js\nimport express, {Router} from 'express';\n\nclass App {\n    app;\n\n    // 앱 생성 시 controller 의존성을 주입받음\n    constructor(controllers) {\n        this.app = express();\n\n        this.initializeControllers(controllers);\n    }\n\n    listen() {\n        const port = process.env.PORT || 3000;\n        this.app.listen(port, () => {\n            logger.info(`App listening on the port ${port}`);\n        });\n    }\n\n    initializeControllers(controllers) {\n        const router = Router();\n        controllers.forEach(controller => {\n            router.use(controller.router);\n        });\n\n        this.app.use('/api', router);\n    }\n}\n```\n\n서비스 중 Exception 이 발생하더라도 원하는 형태의 response 가 내려가도록 인터셉터 개념의 미들웨어를 추가해 줄 필요가 있습니다.\n\n```js\nexport const errorMiddleware = (err, req, res, next) => {\n    const status = err.status || 500;\n    const message = err.message;\n\n    res.status(status).send({\n        success: false,\n        error: {\n            status,\n            message\n        }\n    });\n    \n    next();\n}\n```\n\n이 미들웨어 함수 또한 앱이 생성될 때 확장되도록 구성합니다.\n\n```js\nimport express, {Router} from 'express';\nimport {errorMiddleware} from \"./middleware/error.middleware.js\";\n\nclass App {\n    app;\n\n    constructor(controllers) {\n        this.app = express();\n\n        this.initializeControllers(controllers);\n        this.initializeErrorHandling();\n    }\n\n    listen() {\n        const port = process.env.PORT || 3000;\n        this.app.listen(port, () => {\n            logger.info(`App listening on the port ${port}`);\n        });\n    }\n\n    initializeControllers(controllers) {\n        const router = Router();\n        controllers.forEach(controller => {\n            router.use(controller.router);\n        });\n\n        this.app.use('/api', router);\n    }\n\n    initializeErrorHandling() {\n        this.app.use(errorMiddleware);\n    }\n}\n```\n\n### 데이터베이스 연결성 검사\n\n앱이 구동되기 전 데이터베이스 연결성을 우선 검사하여 서비스가 정상적으로 동작할 수 있는 환경을 검증합니다.\n\nMariaDB 는 커넥션 풀을 생성하고 필요한 경우에만 커넥션을 생성하는 방식으로 구현합니다. 풀을 생성하고 정상적으로 커넥션을\n얻을 수 있는 지 확인하여 연결성을 검증합니다.\n\n```js\nimport mariadb from 'mariadb';\n\nconst mariaConfig = {\n    // db 정보....\n}\n\nexport const pool = mariadb.createPool(mariaConfig);\n\nexport async function mariaCheckConnection() {\n  let conn;\n  try {\n    conn = await pool.getConnection((err, conn) => {\n      if (err) throw err;\n    })\n  } catch (err) {\n    throw err;\n  } finally {\n    if (conn) conn.release();\n  }\n}\n```\n\nredis 데이터베이스로의 연결성을 검증합니다. redis 의 경우 cluster 로 구성되어 있기 때문에 `rs-wrapper` 패키지를 이용하여\n연결합니다.\n\n```js\nimport redisConnector from 'rs-wrapper';\n\nconst redisConfig = {\n    // redis 정보...\n}\n\nredisConnector.config(redisConfig);\n\nexport {redisConnector};\n\nexport async function redisCheckConnection() {\n  let sample = 123;\n  try {\n    await redisConnector.set('init-key', sample, (err) => {\n      if (err) throw err;\n    });\n\n    await redisConnector.get('init-key', (err, result) => {\n      if (err) throw err;\n      else {\n        if (sample !== result) throw Error('Something wrong with redis');\n      }\n    })\n  } catch (err) {\n    throw err;\n  }\n}\n```\n\n어플리케이션이 시작될 때 모두 커넥션을 검사 후 정상이어야 구동이 가능하도록 합니다.\n\n```js\nimport App from \"./app.js\";\nimport {mariaCheckConnection, redisCheckConnection} from '../lib/database.js';\nimport UserController from \"./api/user/user.controller.js\";\n\nasync function startServer() {\n    try {\n        await mariaCheckConnection();\n        await redisCheckConnection();\n    } catch (error) {\n        console.error(error);\n        process.exit();\n    }\n    \n    const app = new App([\n        new UserController(),\n    ]);\n\n    app.listen();\n}\n\nstartServer().then(() => console.log(\"System Initiated\"));\n```\n\n## OpenSearch (ElasticSearch) 쿼리 메서드\n\n자사 클라우드 인프라 내 OpenSearch 에 적재되는 로그는 일정한 패턴을 가집니다.\n이를 아래와 같이 표현하여 반복 코드를 줄일 수 있습니다.\n\n```js\nexport function getBasicTrxSearchQuery(url, method, startDate, endDate) {\n    return {\n        \"sort\": {\n            \"@timestamp\": \"desc\"\n        },\n        \"size\": 100,\n        \"query\": {\n            \"bool\": {\n                \"must\": [\n                    {\"match_phrase\": {\"request.uri\": url}},\n                    {\"match_phrase\": {\"request.method\": method}}\n                ],\n                \"filter\": [\n                    {\"range\": {\"@timestamp\": {\"gte\": startDate, \"lte\": endDate}}}\n                ]\n            }\n        }\n    }\n}\n```\n\n이에 요구 사항에 맞춰 필요한 쿼리는 변형하여 request body 를 구성할 수 있겠습니다. 아래는 uri 에 query parameter 로\n`${userId}` 가 포함되어 있는 로그를 검색하는 예시 코드입니다.\n\n```js\nimport {getBasicTrxSearchQuery} from '../dto/log.request.dto.js';\n\nexport class Repository {\n    findLogsByUserId = async (uri, index, method, userId, startDate, endDate) => {\n        const body = getBasicTrxSearchQuery(uri, method, startDate, endDate);\n        body.query.bool.must.push({\n            \"match\": {\n                \"request.uri\": userId\n            }\n        });\n        return await this.sendQueryToOpenSearch(index, body);\n    }\n    \n    private sendQueryToOpenSearch = async (index, body) => {\n        return await axios.post(`${openSearchHost}/${index}/_search`, body)\n            .then(res => {\n                return res.data.hits.hits;\n            })\n            .catch(err => {\n                throw new Error(err);\n            });\n    }\n}\n```\n\n이와 같이 초기 프로젝트를 구현하고 인수인계를 마쳤습니다.\n\n---\n\n## 트러블 슈팅\n\n히스토리를 전달받지 못해 알 수 없으나 특정 시점에서 서비스에 버그가 발생하였고,\n이 또한 사정을 알 수 없으나 업체 측에서 버그를 해결하지 못한 채로 서비스가 긴 시간 방치되었습니다.\n초기 프로젝트룰 구성하였다는 이유로 트러블 슈팅 업무를 지원하게 됩니다.\n\n관리자 페이지에서 동작하지 않는 기능은 핵심 서비스였던 로그 조회에 관련된 전체 서비스였습니다.\n`500 Internal Server Error` 가 내려오거나 실제 로그가 있음에도 불구하고 조회되지 않는 문제였습니다.\n\n파악한 원인은 아래와 같습니다.\n\n1. 로그를 적재하는 방식이 변경됨\n    - 요청에 각 request, response, trx 이라는 세 개의 로그 타입을 따로 저장하던 방식에서 trx 만 저장하고 request, response 의 내용을 모두 통합함.\n    - 기존 로그 검색 방식은 trx 로그 타입을 제외하고 request, response 만을 검색한 후 `trxId` 를 추출하여 trx 로그를 검색하여 필요한 정보를 필터링 하는 방식이어 이에 1번 내용과 충돌. 아무 로그도 검색되어 나오지 않음.\n2. 검색되어진 로그들에 `filter` 메서드를 적용하는 과정에서 `TypeError` 발생. `undefined` 를 고려하지 않음.\n\n1번 문제는 내부 정책을 변경한 후에 커뮤니케이션이 정상적으로 이루어지지 않은 것으로 보입니다.\n초기 프로젝트 구성 당시 작성한 `BasicTrxSearchQuery` 의 body 를 수정합니다.\n\n2번 문제는 원인이 아주 명확한 코드 상의 오류이므로 이 또한 수정합니다. <s>(타입 안정성을 보장하지 않는 Javascript 싫다!)</s>\n\n---\n\n## 코드 리팩토링\n\n버그 픽스 후 페이지를 테스트 해 보고 프론트엔드 코드를 확인해보는 과정에서 많은 문제들을 확인하였습니다.\n당시 나열한 문제들은 아래와 같습니다.\n\n1. `Header`, `Side NavigationBar` 랜더링 코드가 11개의 파일에서 반복 코딩됨.\n2. `Side NavigationBar` 내 메뉴를 리스트 업하고 navigate 기능을 정의한 코드가 11개의 파일에서 반복 코딩됨.\n3. 로그 조회 결과를 리스트업 하는 테이블의 column 정의가 5개의 파일에서 반복 코딩됨.\n4. 로그인 한 유저만 페이지를 열람할 수 있어야 한다는 정책에 따라 로그인 여부를 확인하는 로직이 11개의 파일에서 반복 코딩됨.\n5. 특정 권한에서만 수행할 수 있는 기능이 존재하는 3개의 페이지에서 권한을 확인하는 로직이 반복 코딩됨.\n6. `useState` hook 사용 중 object 와 같은 mutable type 의 state 를 변경하는 과정에서 오류를 일으킬 수 있는 코드가 다수 존재함.\n7. `axios` 를 사용하는 12개의 페이지에서 패키지를 반복 import 해서 사용하여 설정 확장이 요구될 시 반복 하드 코딩해야 함.\n8. 로그인 시 부여받는 권한을 별도의 암호화 과정 없이 cookie 로 전달받음.\n\n악의가 느껴질 정도의 반복 코드 문제가 대부분입니다. 이는 이 후 유지보수, 확장, 운영을 하는 과정에서 반드시\n문제를 일으킬 코드이기 떄문에 이를 책임자에게 보고하고 별도의 리팩토링 일정을 받았습니다.\n\nReact 프로젝트의 디렉토리 구조를 개선한 것을 간단히 소개하겠습니다.\n\n- `/api`\n- `/components`\n- `/hocs`\n- `/pages`\n- `/routes`\n- `/store`\n- 기타 `/constant`, `/common`, `/utils`\n\n---\n\n### `/api`\n\n`axios` 패키지를 이용한 API 호출 함수들을 정의해 둔 디렉토리 입니다. `axios` 설정을 하여 export 한 후 하위 function 들이 이를\n가져다가 사용하는 방식으로 구현하였습니다.\n\n```js\n// api.js\n\nimport axios from \"axios\";\n\nexport default axios.create({\n    baseURL: process.env.REACT_APP_API_URL,\n    withCredentials: true,\n});\n```\n\n```js\n// user/index.js\n\nimport api from '../api';\nimport {handleResponseError} from \"../../common\";\n\nconst path = \"/api/users\"\n\nexport const getUserInfo = async(userId) => {\n    try {\n        const response = await api.get(path, {params: {userId}});\n        return response.data.result;\n    } catch (error) {\n        // axios 는 2xx response 가 오지 않으면 error 를 발생시킵니다.\n        handleResponseError(error);\n        return null;\n    }\n}\n```\n\n### `/component`\n\n페이지의 주요 컴포넌트 구성을 정의한 내용을 포함하여, `Header`, `Sidebar`, `SearchBar` 등 재사용성이 높은 하위 컴포넌트들을\n구현하였습니다.\n\n### `/hocs`\n\n주요 페이지 컴포넌트들 중 반복적으로 사용되는 로직이 있습니다. 기본적으로 로그인 후 계정 생성 시 부여받은 권한에 따라 사용할 수 있는 기능이\n제한되는 시스템이기 때문에 페이지마다 현재 로그인 되어 있는 사용자의 권한을 체크할 필요가 있었습니다. 이는 매우 반복적이기 때문에 이를\n효율적으로 재사용하기 위한 방법으로 고차 컴포넌트(HOC, Higher Order Component) 개념을 알게 되고 이를 활용하게 되었습니다.\n\n`/hocs` 디렉토리는 이러한 컴포넌트들을 모아놓은 디렉토리입니다.\n\n```js\nimport {useDispatch, useSelector} from \"react-redux\";\nimport {selectAdmin, setUserInfo} from \"../store/adminSlice\";\nimport {useEffect} from \"react\";\nimport {tokenAdmin} from \"../api/admin\";\nimport {message} from \"antd\";\nimport {useNavigate} from \"react-router-dom\";\n\nexport const withCredentials = (WrappedComponent) => {\n    return function WithCredentials(props) {\n        const admin = useSelector(selectAdmin);\n        const dispatch = useDispatch();\n        const navigate = useNavigate();\n        \n        useEffect(() => {\n            // localStorage 내 토큰을 API 서버로부터 검증받고, 토큰 내 유저 정보를 전달받아 store 에 저장.\n        });\n        \n        return (\n            <WrappedComponent {...props}/>\n        )\n    }\n}\n```\n\n### `/pages`\n\n`router` 로 정의되어 있는 타겟 페이지 컴포넌트들을 모아놓은 디렉토리입니다.\n\n### `/routes`\n\n라우터 정의입니다.\n\n```js\nimport React from 'react';\nimport {BrowserRouter as Router, Route, Routes} from 'react-router-dom';\nimport * as Pages from \"../pages\";\n\nconst routes = (\n    <Router>\n        <Routes>\n            <Route path={\"/login\"} element={<Pages.Login/>}/>\n            <Route path={\"/\"} element={<Pages.Main/>}>\n                <Route path={\"/\"} element={<Pages.Home/>}/>\n                <Route path={\"/admin\"} element={<Pages.Admin/>}/>\n            </Route>\n        </Routes>\n    </Router>\n);\n\nexport default routes;\n```\n\n로그인 페이지는 Header, Sidebar 가 없는 페이지 구성이므로 별도로 페이지를 구성하고, 그 외 페이지들은 이 둘을 모두 포함하므로\n아래와 같이 페이지에 `Outlet` 컴포넌트를 정의함으로써 자식 라우터가 호출될 시 `Outlet` 컴포넌트의 위치에 랜더링 되도록 구현하였습니다.\n\n아래와 같이 구현함으로써 페이지를 이동할 때 Header 와 Sidebar 가 모두 같이 렌더링되는..\nReact 라는 반응형 프레임워크를 사용하는 가치를 잃어버리지 않게 할 수 있습니다.\n\n```js\n// Main.js\nimport React from 'react';\nimport {\n    Header as HeaderComponent,\n    Sidebar as SidebarComponent\n} from '../../components';\nimport {Outlet} from \"react-router-dom\";\n\nconst Main = () => {\n    return (\n        <>\n            <HeaderComponent/>\n            <div className={\"content\"}>\n                <SidebarComponent/>\n                <Outlet/>\n            </div>\n        </>\n    )\n}\n\nexport default Main;\n```\n\n### `/store`\n\n`/hocs` 부분에서도 서술했듯 로그인 되어 있는 유저 정보의 경우 거의 대부분의 페이지에서 사용되는 정보이므로 이를 전역 변수처럼 원할 때\n사용 가능하도록 할 필요가 있었습니다. 하지만 전역 변수의 사용은 가급적 지양해야 하므로 안전하게 전역 변수를 관리할 수 있는 `Store` 기능을\n사용하였습니다. 해당 디렉토리는 React 의 `redux` 라이브러리의 설정 및 관리할 state 들을 정의한 디렉토리입니다.\n\n이와 같이 구조를 설계하고 최소 단위의 컴포넌트를 정의하도록 신경써 반복 코드를 최대한 줄일 수 있습니다.\n\n```js\n// store.js\nimport adminReducer from './adminSlice';\nimport {configureStore} from \"@reduxjs/toolkit\";\n\nconst store = configureStore({\n    reducer: {\n        admin: adminReducer\n    }\n});\n\nexport {store};\n```\n\n```js\nimport {createSlice} from \"@reduxjs/toolkit\";\n\nexport const adminSlice = createSlice({\n    name: 'admin',\n    initialState: {\n        admin: {\n            status: false,\n            userId: \"\",\n            role: \"\",\n            token: \"\",\n            exp: 0\n        }\n    },\n    reducers: {\n        setUserInfo: (state, action) => {\n            state.admin = {...action.payload}\n        },\n    }\n})\n\nexport const {setUserInfo} = adminSlice.actions;\n\nexport const selectAdmin = state => state.admin.admin;\n\nexport default adminSlice.reducer;\n```\n\n---\n\n23년 3월 6일부로 외주 업체 인력이 충원됨에 따라 프로젝트를 인수 인계 하였습니다."},{"id":1,"title":"관리자 페이지 - 버전 등록 페이지 개발","date":"2022-12-17","tag":["Spring Boot","Spring JPA","Spring Web","QueryDSL","Vue.js"],"content":"\n- 기간: 2022. 11 ~ 2022. 12, 약 2개월\n- 주요 업무: 코맥스 클라우드 2.0 어드민 페이지 내 리소스 버전 등록 페이지 개발\n- 업무 목적: 실제 유통된 리소스(월패드, 로비폰 등) 내 어플리케이션 버전 등록/업데이트를 위한 페이지 개발\n- 개발 인원: 1인\n- 프로젝트 스펙\n    - Spring Boot\n    - Spring Web MVC\n    - Spring Security\n    - QueryDSL\n    - Vue.js\n\n기존 코맥스 클라우드 2.0 의 관리자 페이지에 OTA(Over The Air) 기능을 추가하는 개발 건의\n여러 요구사항 중 신규 버전 등록을 위한 페이지를 개발하는 업무를 담당하게 되었습니다.\n\n---\n\n## 프로젝트 구조 분석\n\n기본적으로 Spring Web MVC 프레임워크를 사용한 프로젝트로 Apache Tiles 라이브러리를 사용하여\n타일 기반의 레이아웃을 구현한 것으로 보입니다.\n\n```java\n\n@Configuration\npublic class WebMvcConfig implements WebMvcConfigurer {\n    public void configureViewResolvers(ViewResolverRegistry registry) {\n        TilesViewResolver viewResolver = new TilesViewResolver();\n        registry.viewResolver(viewResolver);\n    }\n\n    @Bean\n    public TilesConfigurer tilesConfigurer() {\n        TilesConfigurer tilesConfigurer = new TilesConfigurer();\n        tilesConfigurer.setDefinitions(new String[]{\n            \"/WEB-INF/layouts/**/*.tiles.xml\",\n            \"/WEB-INF/views/**/*.tiles.xml\"\n        });\n        tilesConfigurer.setCheckRefresh(true);\n        return tilesConfigurer;\n    }\n}\n```\n\n여러 많은 타일들이 정의되어 있지만 가장 핵심으로 보이는 레이아웃 구성은 아래 코드입니다.\n\n```html\n<!--page.layout.jsp-->\n<html lang=\"ko\">\n<head>\n    <title></title>\n    <!--....-->\n</head>\n<body>\n<div class=\"page-container\">\n    <div class=\"page-content\">\n        <tiles:insertAttribute name=\"leftmenu\"/>\n        <div class=\"content-wrapper\">\n            <div class=\"content\">\n                <tiles:insertAttribute name=\"body\"/>\n                <tiles:insertAttribute name=\"footer\"/>\n            </div>\n        </div>\n    </div>\n</div>\n</body>\n</html>\n```\n\n메인 페이지의 레이아웃을 정의한 모습입니다. 아주 간단해 보이는 HTML 구성이며, body attribute 에 구현한 레이아웃을 삽입할 수 있는 것으로 보입니다. 이 구성에\n맞춰 `/WEB-INF/views/resource/resourcevermng` 라는 버전 관리 페이지의 디렉토리를 생성해주고 `views.tiles.xml` 파일을 생성하여 새로 만들 타일의 설정을 해주었습니다.\n\n```html\n\n<tiles-definitions>\n    <definition name=\"resource/resourcevermng/*\" extends=\"page.layout\">\n        <put-attribute name=\"body\" value=\"/WEB-INF/views/resource/resourcevermng/{1}.jsp\"/>\n    </definition>\n</tiles-definitions>\n```\n\n`resourcemng.jsp` 파일을 생성하여 실제 랜더링 될 페이지의 템플릿을 정의합니다. 페이지를 구성하는 프레임워크는 Vue.js 이므로 Vue.js 의 템플릿 문법에 대한 기억을 더듬어가며 코딩하였습니다.\n세부 코드는 생략합니다.\n\n```html\n\n<div id=\"rootVM\" v-cloak>\n    <!--...-->\n</div>\n\n<script type=\"text/javascript\" src=\"${contextPath}/app/resource/resourcevermng/resourcevermng.js\"/>\n```\n\n최초 프로젝트를 구현한 분의 의도를 정확히 파악할 수는 없으나, 한 파일에 template 과 script 코드가 모두 다 들어가 가독성을 해치는 것을 방지하기 위함이 아니었을까 생각됩니다. `contextPath`\n는 constant 전역 변수로써 `/src/resources/static` 입니다.\n\n`src` attribute 에 정의된 파일을 생성하고 코드를 작성하였습니다. 세부 코드는 생략합니다.\n\n```js\nconst rootVM = new Vue({\n    name: 'RootVM',\n    el: '#rootVM',\n    created() {\n    },\n    data: {},\n    computed: {},\n    methods: {}\n})\n```\n\n페이지 레이 아웃의 구성을 마쳤으니 이제 Resolver 가 `resource/resourcevermng/*` 이름의 타일을 불러올 수 있도록 컨트롤러 메서드를 구현합니다.\n\n```java\n\n@Controller\n@RequestMapping(\"/resource/resourcevermng\")\npublic class ResourceVersionManageController {\n\n    @GetMappging(\"/\")\n    public String index(Model model) {\n        // model.addAttribute()  필요한 데이터를 보내줍니다.\n        return \"/resource/resourcevermng/resourcevermng\";\n    }\n}\n```\n\n---\n\n### QueryDSL\n\n요구되는 페이지 기능 상 쿼리가 필요하기 때문에 그에 관련 된 구조 또한 파악할 필요가 있었습니다. Spring 의 ORM 스펙 중 하나인 `QueryDSL`\n을 사용하고 있습니다. 부분 필터링 기능을 구현해야 하는 어드민 페이지이었기 때문에 `QueryDSL` 채택은 아주 합리적이라고 생각합니다.\n\n실제 구현한 코드를 예시로 들며 설명해보겠습니다.\n\n![ota_resource_vermng](/images/ota/1.png)\n\n화면에 보이듯 총 7개의 검색 필드가 존재하는데 7개의 필드를 모두 다 채워 검색해야 한다면 사용성이 매우 떨어지니 당연히 일부 필드만 채워 검색하더라도 필터가 적용된 검색 결과를 보여주어야 합니다. 이를 JPA 의\n일반적인 쿼리 메서드로 구현한다고 하면 이 한 기능을 위해 수도 없이 많은 메서드를 정의해야 했을 것입니다.\n\n```java\n// 실제 코드가 아닌 예시입니다.\n\n@Repository\npublic interface ResourceVersionRepository extends JpaRepository<ResourceVersion, Long> {\n    List<ResourceVersion> findByModelName(String modelName);\n\n    List<ResourceVersion> findByModelNameAndModelType(String modelName, String modelType);\n\n    List<ResourceVersion> findByModelNameAndModelTypeAndVersion(String modelName, String modelType, String version);\n    // .....수십개의 method T_T\n}\n```\n\n이런 상황에서는 동적 쿼리가 작성 가능한 방법을 찾아야 하는데 `QueryDSL` 은 이를 해결해줄 JPQL 빌더입니다.\n\n기존 설정이 이미 완료되어 있고 컴파일 시 `/target/generated-sources/java/{package}/entity` 아래 QModel 들이 생성되는 것을 확인하였으니 추가된 테이블을 정의합니다. 실제\n코드와는 다른 예시입니다.\n\n```java\n\n@Entity\n@Getter\n@Setter\n@Table(name = \"tbl_resource_version\")\npublic class ResourceVersion {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    @Column(columnDefinition = \"int\")\n    private Long seqno;\n\n    @ManyToOne(fetch = FetchType.LAZY)\n    @JoinColumn(name = \"modelSeqno\")\n    private ResourceModel model;\n\n    private String version;\n\n    private String registerAdmin;\n\n    private String updateAdmin;\n\n    @Column(columnDefinition = \"int\")\n    private Long registerTs;\n\n    @Column(columnDefinition = \"int\")\n    private Long updateTs;\n}\n```\n\n이 후 다시 컴파일하면 `QResourceVersion` 이라는 새로운 QModel 이 생성된 것을 볼 수 있습니다.\n\n```java\n\n@Generated(\"com.querydsl.codegen.EntitySerializer\")\npublic class QResourceVersion extends EntityPathBase<ResourceVersion> {\n    //...\n}\n```\n\n동적 쿼리를 작성합니다. 역시 실제 코드와 다른 예시입니다.\n\n```java\n\n@Repository\npublic class ResourceVersionRepository {\n\n    @Autowired\n    private JPAQueryFactory queryFactory;\n\n    /**\n     * SearchMap 은 ServletRequest 를 HashMap<String, Object> 의 형태로 변환시킨 객체입니다.\n     */\n    public QueryResults<Tuple> queryVersionList(SearchMap map, Sort sort) {\n        BooleanBuilder filter = new BooleanBuilder();\n        QResourceVersion v = new QResourceVersion(\"v\");\n        QResourceModel m = new QResourceModel(\"m\");\n\n        if (map != null) {\n            String modelName = (String) map.get(\"modelName\");\n            String modelType = (String) map.get(\"modelType\");\n            String version = (String) map.get(\"version\");\n\n            // 동적 쿼리 조건문 추가 \n            if (modelName != null) filter.and(m.modelName.eq(modelName));\n            if (modelType != null) filter.and(m.modelType.eq(modelType));\n            if (version != null) filter.and(v.version.eq(version));\n\n            // 쿼리 실행\n            JPAQuery<Tuple> query = queryFactory\n                .select(m.modelName, m.modelType, v.version)\n                .from(v)\n                .leftJoin(v.model(), m)\n                .where(filter);\n\n            return query.fetResults();\n        } else {\n            // 필터 없이 전체 검색...\n        }\n    }\n}\n```\n\n이 후 `QueryResults<Tuple>` 형태의 결과값은 DTO 형태로 변환하여 페이지에 전달하도록 구현하였습니다.\n\n---\n\n## AWS S3 에 바이너리 업로드\n\nJavaScript 용 AWS SDK 가\n있습니다. [공식 문서](https://docs.aws.amazon.com/ko_kr/sdk-for-javascript/v2/developer-guide/welcome.html) 를 참고하여 AWS S3 에 업로드가\n가능하도록 구현하였습니다.\n\n앞단은 엄밀히 따지자면 Node.js 프로젝트가 아니므로 브라우저 스크립트로 SDK 를 포함시켜야 했습니다.\n\n```html\n<!--resourcevermng.jsp-->\n\n<!-- ..... -->\n<script src=\"https://sdk.amazonaws.com/js/aws-sdk-2.1254.0.min.js></script>\n```\n\nAWS 접근 권한을 부여하기\n위해 [공식 문서](https://docs.aws.amazon.com/ko_kr/sdk-for-javascript/v2/developer-guide/getting-started-browser.html) 의 1단계,\n2단계 내용을 참고하여 CognitoIdentity Pool 을 생성하고 정책을 부여하였습니다. 이 후 권한을 가진 Pool ID 를 받을 수 있습니다. 이를 바탕으로 포함시킨 SDK 를 확장합니다.\n\n마지막으로 역시 공식 문서를 참조하여 페이지에서 전달받은 바이너리 파일을 AWS S3에 업로드 하였습니다.\n\n```js\nasync function uploadFileToS3() {\n    // ...v-model > closure. file 에 관한 정보를 가져옴\n    \n    var credentials = new AWS.CognitoIdentityCredentials({\n        IdentityPoolId: 'ap-northeast-2:key...'\n    });\n    AWS.config.update({\n        region: 'ap-northeast-2',\n        credentials,\n    });\n    let s3 = new AWS.s3({\n        computeChecksums: true\n    });\n    let body = {\n        Bucket: 'bucket-name',\n        Body: file,\n        Key: fileName\n    }\n    const putResult = await s3.putObject(body).promise();\n}\n\n```\n\n"}]},"__N_SSG":true}